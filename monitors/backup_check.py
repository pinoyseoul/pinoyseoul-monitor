# -*- coding: utf-8 -*-
"""
Monitors the health and integrity of rclone backups by parsing log files
and checking backup artifacts.
"""

import os
import re
import datetime
import logging
from typing import Dict, Any, Optional

from utils.google_chat import send_alert

# Set up a logger for this module
log = logging.getLogger(__name__)

# --- Log Parsing Logic ---

def _parse_rclone_log(log_path: str, max_age_hours: int) -> Optional[Dict[str, Any]]:
    """
    Parses an rclone log file to find the latest completed backup summary,
    matching the specific output format generated by the backup.sh script.
    """
    log.info(f"Parsing rclone log at '{log_path}' for entries in the last {max_age_hours} hours.")
    try:
        with open(log_path, 'r') as f:
            content = f.read()
    except Exception as e:
        log.error(f"Could not read log file {log_path}: {e}")
        return None

    # Find all backup blocks in the log file
    blocks = re.findall(r"=== Starting backup at.*?===\n(.*?)\n=== Backup complete! ===", content, re.DOTALL)
    if not blocks:
        log.warning("No complete backup blocks found in log file.")
        return None

    # The last block is the most recent one
    latest_block = blocks[-1]

    # --- Find Timestamp ---
    # Find the first rclone timestamp in the block
    time_match = re.search(r"(\d{4}/\d{2}/\d{2}\s\d{2}:\d{2}:\d{2})", latest_block)
    if not time_match:
        log.warning("Could not find a valid timestamp in the latest backup block.")
        return None
    
    log_time = datetime.datetime.strptime(time_match.group(1), '%Y/%m/%d %H:%M:%S')
    if (datetime.datetime.now() - log_time) > datetime.timedelta(hours=max_age_hours):
        log.warning(f"Found a backup summary from {log_time}, but it is older than the {max_age_hours} hour threshold.")
        return None

    # --- Parse Block for Details ---
    # Transferred:   	   60.380M / 60.380 MBytes, 100%, 14.770 MBytes/s, ETA 0s
    size_match = re.search(r"Transferred:\s*.*?/\s*([\d\.]+)\s*(G|M|k|B)Bytes", latest_block)
    # Transferred:            1 / 1, 100%
    files_match = re.search(r"Transferred:\s*(\d+)\s*/", latest_block)
    # Elapsed time:         5.3s
    duration_match = re.search(r"Elapsed time:\s*([\w\.]+)", latest_block)
    # Errors: 1 (retrying may help)
    errors_match = re.search(r"Errors:\s*(\d+)", latest_block)

    # --- Data Extraction ---
    errors = int(errors_match.group(1)) if errors_match else 0
    
    if not all([size_match, files_match, duration_match]):
        # If there was an error, the summary block might be malformed.
        # But if we found an error count, that's the most important thing.
        if errors > 0:
            log.warning("Backup block seems incomplete, but an error count was found.")
            return {'log_time': log_time, 'errors': errors, 'size_mb': 0, 'files': 0, 'duration_minutes': 0}
        
        log.error("Failed to parse essential details (size, files, duration) from the latest backup block.")
        return None

    size_val = float(size_match.group(1))
    size_unit = size_match.group(2).upper()
    if size_unit == 'G': size_mb = size_val * 1024
    elif size_unit == 'M': size_mb = size_val
    elif size_unit == 'K': size_mb = size_val / 1024
    else: size_mb = size_val / (1024 * 1024)

    files = int(files_match.group(1))
    
    duration_str = duration_match.group(1)
    total_minutes = 0
    if 'h' in duration_str:
        h_match = re.search(r"(\d+)h", duration_str)
        if h_match: total_minutes += int(h_match.group(1)) * 60
    if 'm' in duration_str:
        m_match = re.search(r"(\d+)m", duration_str)
        if m_match: total_minutes += int(m_match.group(1))
    
    log.info(f"Successfully parsed a recent backup summary from {log_time}.")
    return {
        'log_time': log_time, 'errors': errors, 'size_mb': round(size_mb, 2),
        'files': files, 'duration_minutes': total_minutes
    }


def check_backup_health(config: Dict[str, Any]) -> Dict[str, Any]:
    """
    Performs a multi-layered check on the latest rclone backup by parsing logs.
    """
    log_path = config.get('log_path')
    min_size_mb = config.get('min_size_mb', 100)
    max_age_hours = config.get('max_age_hours', 25)

    result = {
        'status': 'error', 'last_backup_time': None, 'backup_size_mb': 0,
        'files_backed_up': 0, 'duration_minutes': 0, 'message': 'Check did not run'
    }

    if not log_path or not os.path.exists(log_path):
        msg = f"Rclone log file not found at '{log_path}'."
        log.error(msg)
        send_alert("Backup Log Missing", severity="critical", title="Backup Check Failed", details=msg)
        result['message'] = msg
        return result

    parsed_data = _parse_rclone_log(log_path, max_age_hours)

    if not parsed_data:
        msg = f"No valid backup summary found in the last {max_age_hours} hours."
        log.critical(msg)
        send_alert("Backup Failed", severity="critical", title="Backup Check Failed",
                   details="Last night's backup may not have completed. Nash investigating.")
        result.update({'message': msg, 'status': 'failed'})
        return result

    result.update({
        'last_backup_time': parsed_data['log_time'], 'backup_size_mb': parsed_data['size_mb'],
        'files_backed_up': parsed_data['files'], 'duration_minutes': parsed_data['duration_minutes'],
    })

    if parsed_data['errors'] > 0:
        result['status'] = 'failed'
        result['message'] = f"Backup completed with {parsed_data['errors']} errors."
        log.critical(result['message'])
        send_alert("Backup Failed", severity="critical", title="Backup Completed with Errors",
                   details=f"{result['message']} Nash investigating.")
    elif parsed_data['size_mb'] < min_size_mb:
        result['status'] = 'failed'
        result['message'] = f"Backup size {parsed_data['size_mb']} MB is below threshold of {min_size_mb} MB."
        log.critical(result['message'])
        send_alert("Backup Failed", severity="critical", title="Backup Size Anomaly",
                   details=f"{result['message']} This may indicate an incomplete backup. Nash investigating.")
    else:
        result['status'] = 'success'
        result['message'] = f"Backup completed successfully at {parsed_data['log_time'].strftime('%Y-%m-%d %H:%M')}. Size: {parsed_data['size_mb']} MB."
        log.info(result['message'])

    return result
